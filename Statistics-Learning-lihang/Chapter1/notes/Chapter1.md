# $\xi1$ 统计学习及监督学习概论



## $\xi1.1$ 统计学习

​	统计学习的基本概念，忽略。

## $\xi1.2$ 统计学习的分类

### $\xi1.2.1$ 基本分类

+ 监督学习
+ 无监督学习
+ 强化学习
+ 半监督学习
+ 主动学习

#### 监督学习

+ 监督学习是指从标注数据中学习预测模型的机器学习问题。

+ 关于几个空间

  |       名称       |                             意义                             |
  | :--------------: | :----------------------------------------------------------: |
  |  输入空间$\chi$  |                    输入所有可能取值的集合                    |
  | 输出空间$\cal Y$ |                    输出所有可能取值的集合                    |
  |     特征空间     |                    所有特征向量存在的空间                    |
  | 假设空间$\cal F$ |               从输入空间到输出空间的映射的集合               |
  |     参数空间     | 假设$\cal F$定义为决策函数， $\cal F = \{f|Y=f_{\theta}(x),\theta \in \bf R ^n \}$ |
  |     参数空间     | 假设$\cal F$定义为条件概率分布， $\cal F = \{P|P_{\theta}(Y|X),\theta \in \bf R ^n \}$ |

  

#### 无监督学习

+ 无监督学习是指从无标注数据中学习预测模型的机器学习问题。
+ 无监督学习模型的本质是学习数据中的统计规律或潜在结构，旨在从假设空间中选出在给定评价标准下的最优模型。

#### 强化学习

+ 强化学习是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。
+ 假设智能系统和环境的互动基于马尔可夫决策过程，在每一步t中，智能系统从环境中观测到一个状态$s_t$ 与下一个奖励 $r_t$，采取一个动作$a_t$。
  + 下一个状态只依赖于前一个状态和动作。
  + 下一个奖励只依赖于前一个状态和动作。
+ 策略$\pi$定义为给定状态下动作的函数 $a = f(s)$ 或者条件概率分布$P(a|s)$。
+ 价值函数定义为策略$\pi$从某一状态s开始的长期累计奖励的数学期望。
+ 动作价值函数定义为策略$\pi$从某一状态s和动作a开始的长期累计奖励的数学期望。
+ 强化学习的目标就是在所有可能的策略中选出价值函数最大的策略$\pi ^ *$。

#### 半监督学习

+ 半监督学习是指利用标注数据和未标注数据学习预测模型的机器学习问题。
+ 为标注数据辅助标注数据进行监督学习。

#### 主动学习

+ 主动学习是指机器不断主动给实例让教师进行标注。

### $\xi1.2.2$ 按模型分类

#### 概率模型和非概率模型

+ 取条件概率分布还是函数形式。

#### 线性模型和非线性模型

+ 在非概率模型中，函数形式是线性与否。

#### 参数模型和非参数模型

+ 参数的维度固定与否。

### $\xi1.2.3$ 按算法分类

#### 在线学习

#### 批量学习

### $\xi1.2.4$ 按技巧分类

#### 贝叶斯学习

#### 核方法

------

**以下部分为[SmirkCao](https://github.com/SmirkCao/Lihang)的内容**

## $\xi1.3$ 统计学习方法三要素

### $\xi1.3.1$ 模型

#### 模型是什么?

在监督学习过程中，模型就是所要学习的**条件概率分布**或者**决策函数**。

注意书中的这部分描述，整理了一下到表格里：

|              | 假设空间$\cal F$                                             | 输入空间$\cal X$ | 输出空间$\cal Y$ | 参数空间      |
| ------------ | ------------------------------------------------------------ | ---------------- | ---------------- | ------------- |
| 决策函数     | $\cal F\it =\{f_{\theta} |Y=f_{\theta}(x), \theta \in \bf R \it ^n\}$ | 变量             | 变量             | $\bf R\it ^n$ |
| 条件概率分布 | $\cal F\it =\{P|P_{\theta}(Y|X),\theta\in \bf R \it ^n\}$    | 随机变量         | 随机变量         | $\bf R\it ^n$ |



书中描述的时候，有提到**条件概率分布族**，这个留一下，后面2[CH06](../CH06/README.md)有提到确认逻辑斯谛分布属于指数分布族。

### $\xi1.3.2$ 策略

#### 损失函数与风险函数

> **损失函数**度量模型**一次预测**的好坏，**风险函数**度量**平均意义**下模型预测的好坏。

1. 损失函数(loss function)或代价函数(cost function)
   损失函数定义为给定输入$X$的**预测值$f(X)$**和**真实值$Y$**之间的**非负实值**函数，记作$L(Y,f(X))$

2. 风险函数(risk function)或期望损失(expected loss)
   这个和模型的泛化误差的形式是一样的
   $R_{exp}(f)=E_p[L(Y, f(X))]=\int_{\mathcal X\times\mathcal Y}L(y,f(x))P(x,y)\, {\rm d}x{\rm d}y$
   模型$f(X)$关于联合分布$P(X,Y)$的**平均意义下的**损失(**期望**损失)，但是因为$P(X,Y)$是未知的，所以前面的用词是**期望**，以及**平均意义下的**。

   这个表示其实就是损失的均值，反映了对整个数据的预测效果的好坏，P(x,y)$转换成$\frac {\nu(X=x, Y=y)}{N}$更容易直观理解, 可以参考[CH09](../CH09/README.md)，6.2.2节的部分描述来理解，但是真实的数据N是无穷的。

3. **经验风险**(empirical risk)或**经验损失**(empirical loss)
   $R_{emp}(f)=\frac{1}{N}\sum^{N}_{i=1}L(y_i,f(x_i))$
   模型$f$关于**训练样本集**的平均损失
   根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险

4. **结构风险**(structural risk)
   $R_{srm}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)$
   $J(f)$为模型复杂度, $\lambda \geqslant 0$是系数，用以权衡经验风险和模型复杂度。

#### 常用损失函数

损失函数数值越小，模型就越好

$L(Y,f(X))$

1. 0-1损失
   $L=\begin{cases}1, Y \neq f(X) \\0, Y=f(X) \end{cases}$
2. 平方损失
   $L=(Y-f(X))^2$
3. 绝对损失
   $L=|Y-f(X)|$

$L(Y,P(Y|X))$

1. 对数损失
   这里$P(Y|X)\leqslant 1$，对应的对数是负值，所以对数损失中包含一个负号，为什么不是绝对值？因为肯定是负的。
   $L=-\log P(Y|X)$

#### ERM与SRM

经验风险最小化(ERM)与结构风险最小化(SRM)

1. **极大似然估计**是经验风险最小化的一个例子
   当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价于极大似然估计
2. **贝叶斯估计**中的**最大后验概率估计**是结构风险最小化的一个例子
   当模型是条件概率分布，损失函数是对数损失函数，**模型复杂度由模型的先验概率表示**时，结构风险最小化等价于最大后验概率估计

### $\xi1.3.3$ 算法

这章里面简单提了一下，具体可以参考[CH12](../CH12/README.md)表格中关于学习算法的描述。

## $\xi1.4 $ 模型评估与模型选择

训练误差和测试误差是模型关于数据集的平均损失。

提到一句， `统计学习方法具体采用的损失函数未必是评估时使用的损失函数`，这句理解下。参考下在数据科学比赛中给出的评分标准，与实际学习采用的损失函数之间的关系。

### $\xi1.4.1 $ 过拟合与模型选择

这部分讲到了最小二乘法，给了PRML中的一个例子。

这个问题中**训练数据**为
$$
T=\{(x_1, y_1),(x_2,y_2),\cdots,(x_N,y_N)\}
$$
**模型**为
$$
f_M(x,w)=w_0+w_1x+w_2x^2+\cdots+w_Mx^M=\sum\limits_{j=0}^Mw_jx^j
$$
经验风险最小化策略下
$$
L(w)=\frac{1}{2}\sum\limits_{i=1}^N(f(x_i,w)-y_i)^2
$$
将模型和训练数据带入到上式得到
$$
L(w)=\frac{1}{2}\sum\limits_{i=1}^N\left(\sum\limits_{j=0}^Mw_jx_i^j-y_i\right)^2=\frac{1}{2}\sum\limits_{i=1}^N(w\cdot x_i-y_i)^2
$$
这个问题要求
$$
w=(w_0^*,w_1^*,\cdots,w_M^*)
$$
对$w$求偏导令其为零，得到一系列方程，求解可以用梯度下降或者矩阵分解。

求解线性方程组
$$
Ax=b
$$
，可以表示为
$$
x=A/b
$$
，问题展开之后可以涉及到**矩阵分解**。

TODO: 这个例子展开一下

## $\xi1.5 $ 正则化与交叉验证

1. 正则化
   模型选择的典型方法是正则化
2. 交叉验证
   另一种常用的模型选择方法是交叉验证
   - 简单
   - S折(K折, K-Fold)[^1]
   - 留一法

## $\xi1.6 $ 泛化能力

- 现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力

- 统计学习理论试图从理论上对学习方法的泛化能力进行分析

- 学习方法的泛化能力往往是通过研究泛化误差的**概率上界**进行的, 简称为泛化误差上界(generalization error bound)

  这本书里面讨论的不多，在[CH08](../CH08/README.md)里面有讨论提升方法的误差分析, 提到$AdaBoost$不需要知道下界$\gamma$。在[CH02](../CH02/README.md)中讨论算法的收敛性的时候有提到误分类次数的上界.

注意泛化误差的定义，书中有说**事实上，泛化误差就是所学习到的模型的期望风险**



## $\xi1.7 $ 生成模型与判别模型

**监督学习方法**可分为**生成方法**(generative approach)与**判别方法**(discriminative approach)

### 生成方法

generative approach

- 可以还原出**联合概率分布**$P(X,Y)$
- 收敛速度快, 当样本容量增加时, 学到的模型可以更快收敛到真实模型
- 当存在隐变量时仍可以用

### 判别方法

discriminative approach

- 直接学习**条件概率**$P(Y|X)$或者**决策函数**$f(X)$
- 直接面对预测, 往往学习准确率更高
- 可以对数据进行各种程度的抽象,  定义特征并使用特征, 可以简化学习问题

## $\xi1.8 $ 分类问题、标注问题、回归问题

Classification, Tagging, Regression

- 图1.4和图1.5除了分类系统和标注系统的差异外，没看到其他差异，但实际上这两幅图中对应的输入数据有差异，序列数据的$x_i = (x_i^{(1)},x_i^{(2)},\dots,x_i^{(n)})^T$对应了
- 图1.5和图1.6，回归问题的产出为$Y=\hat f(X)$

