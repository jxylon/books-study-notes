# $\xi4$ k近邻法

[TOC]

## $\xi4.1$ 朴素贝叶斯的学习和分类

+ 朴素贝叶斯法是基于贝叶斯定理和特征条件独立假设的分类方法。

### $\xi4.1.1$ 基本方法

+ 朴素贝叶斯法通过训练数据集学习联合概率分布P(X,Y)。
+ 先验概率分布
  
  + $P(Y=c_k)，k = 1,2,...,K$
+ 条件概率分布
  
+ $P(X=x|Y=c_k) =P(X^{(1)},\dots,X^{(n)}|Y=c_k)$
  
+ 于是学习到联合概率分布$P(X,Y)$

+ 书中有这样一段内容

  > 条件概率分布$P(X=x|Y=c_k)$有指数级数量的参数，其实际估计是不可行的。

+ 条件独立假设

  求$P(Y|X)$，其中$X\in\{X_1,X_2,\dots,X_n\}$，条件独立假设这里给定$Y$的情况下：

  1. 每一个$X_i$和其他的每个$X_k$是条件独立的
  2. 每一个$X_i$和其他的每个$X_k$的子集是条件独立的

  条件独立性假设是:
  $$
  \begin{align}
  P(X=x|Y=c_k)&=P(X^{(1)},\dots,X^{(n)}|Y=c_k)\\
  &=\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)
  \end{align}
  $$
  条件独立假设等于是说用于分类的**特征**在**类确定**的条件下都是**条件独立**的。

+ 

### $\xi4.1.2$ 后验概率最大化的含义

+ 朴素贝叶斯法将实例分到后验概率最大的类中，这等价于期望风险最小化。

## $\xi4.2$ 朴素贝叶斯的参数估计

### $\xi4.2.1$ 极大似然估计

+ > 为了估计状态变量的条件分布，利用贝叶斯法则，有
  > $$
  > \underbrace{P(X|Y)}_{posterior}=\frac{\overbrace{P(Y|X)}^{likelihood}\overbrace{P(X)}^{prior}}{\underbrace{P(Y)}_{evidence}}=\frac{\overbrace{P(Y|X)}^{likelihood}\overbrace{P(X)}^{prior}}{\underbrace{\sum\limits_x P(Y|X)P(X)}_{evidence}}
  > $$
  > 其中$P(X|Y)$为给定$Y$下$X$的后验概率(Posterior)， $P(Y|X)$称为似然，$P(X)$称为先验(Prior)。

+ 后验概率最大化的含义

  朴素贝叶斯法将实例分到**后验概率最大的类**中， 这等价于**期望风险最小化**。

### $\xi4.2.2$ 学习与分类算法

+ 步骤
1. 计算先验概率 $P(Y = c_k) = \frac{\sum^n_{i=1}I(y_i = c_k)}{N},  k = 1,2,\dots,K$
  2. 计算条件概率 $P(X^{(j)} = a_{jl}|Y = c_k) = \frac{\sum^N_{i=1}I(x_i^{(j)}=a_{jl},y_i = c_k)}{\sum^N_{i=1}I(y_i = c_k)}%=$
3. 计算给定实例的概率 $P(Y = c_k) \prod^n_{j=1}P(X^{(j)} = a_{jl}|Y = c_k)$
  4. 确定实例x的类 $y = \arg\max_{c_k} P(Y = c_k) \prod^n_{j=1}P(X^{(j)} = a_{jl}|Y = c_k)$

### $\xi4.2.3$ 贝叶斯估计

+ 对于$x$的某个特征的取值没有在先验中出现的情况 ，如果用极大似然估计，这种情况的可能性就是0。
  但是出现这种情况的原因通常是因为数据集不能全覆盖样本空间，出现未知的情况处理的策略就是做平滑。
  公式(4.10)对应了出现未知样本的情况下，该给出一个什么样的值才合理的方案。
  $$
  P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits_{i=1}^NI(x_i^{j}=a_{jl},y_j=c_k)+\lambda}{\sum\limits_{i=1}^NI(y_j=c_k)+S_j\lambda}
  $$
  其中$\lambda \geq 0$

  当$\lambda = 0$的时候，就是极大似然估计。

  当$\lambda=1$的时候，这个平滑方案叫做Laplace Smoothing。拉普拉斯平滑相当于给未知变量给定了先验概率。

## $\xi4.3$ 其他

+ 朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布$P(X,Y)$,然后求得后验概率分布$P(Y|X)$，得到联合概率分布$P(X,Y) = P(Y)P(X|Y)$
+ 估计方法可以是极大似然估计或则贝叶斯估计。
+ 朴素贝叶斯的基本假设是条件独立性。
+ 后验概率最大等价于0-1损失函数时的期望风险最小化。